{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity checks for annotation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING = 'Mac Roman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('AnnotationTable_byArticle.xlsx')\n",
    "people_cols = [column for column in list(df.columns) if 'people' in column and len(column) > len('people')]\n",
    "source_cols = [column for column in list(df.columns) if 'sources' in column]\n",
    "json_files = ['JSON_files_with_gender/'+f for f in os.listdir('JSON_files_with_gender/') if f.endswith('.json')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excel Assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excelAssertions(row):\n",
    "\n",
    "    def customError(key, check, stacktrace=None):\n",
    "        if stacktrace is None:\n",
    "            stacktrace = []\n",
    "        \n",
    "        errorMsg = 'FAILED ASSERTION: '\n",
    "\n",
    "        if check is 'subset':\n",
    "            errorMsg += key + ' not subset of people'\n",
    "            stacktrace.append(key + ': ' + row[key])\n",
    "            stacktrace.append('people: ' + row['people'])\n",
    "        if check is 'superset':\n",
    "            errorMsg += 'people not superset of ' + key\n",
    "            stacktrace.append('people: ' + row['people'])\n",
    "            stacktrace.append(key + ': ' + row[key])\n",
    "        if check is 'eval':\n",
    "            errorMsg += 'Error evaluating ' + key + ' as list'\n",
    "        if check is 'disjoint':\n",
    "            errorMsg += key + ' not disjoint'\n",
    "\n",
    "        errorMsg += ', ' + row['_id']\n",
    "        \n",
    "        if len(stacktrace) > 0:\n",
    "            for trace in stacktrace:\n",
    "                errorMsg += '\\n' + str(trace)\n",
    "        \n",
    "        return errorMsg + '\\n'\n",
    "    \n",
    "    excel_dict = {}\n",
    "    assertion_count = 0\n",
    "    assertion_errors = ''\n",
    "    \n",
    "    people = set()\n",
    "    try:\n",
    "        people = set(eval(row['people']))\n",
    "    except SyntaxError as e:\n",
    "        assertion_count += 1\n",
    "        assertion_errors += customError('people', 'eval', [row['people']])\n",
    "    \n",
    "    for col in people_cols + source_cols:\n",
    "        excel_dict[col] = set()\n",
    "        try:\n",
    "            excel_dict[col] = set(eval(row[col]))\n",
    "        except SyntaxError as e:\n",
    "            assertion_count += 1\n",
    "            assertion_errors += customError('people', 'eval', [row['people']])\n",
    "    \n",
    "    if assertion_count > 0:\n",
    "        raise AssertionError(assertion_errors)\n",
    "        \n",
    "    for i in range(len(people_cols)):\n",
    "        for j in range(i+1, len(people_cols)):\n",
    "            assert excel_dict[people_cols[i]].isdisjoint(excel_dict[people_cols[j]]), customError(\n",
    "                people_cols[i] + ', ' + people_cols[j], 'disjoint')\n",
    "            \n",
    "    for i in range(len(source_cols)):\n",
    "        for j in range(i+1, len(source_cols)):\n",
    "            assert excel_dict[source_cols[i]].isdisjoint(excel_dict[source_cols[j]]), customError(\n",
    "                source_cols[i] + ', ' + source_cols[j], 'disjoint')\n",
    "    \n",
    "    for key in excel_dict.keys():\n",
    "        if not excel_dict[key].issubset(people):\n",
    "            assertion_count += 1\n",
    "            assertion_errors += customError(key, 'subset')\n",
    "        if not people.issuperset(excel_dict[key]):\n",
    "            assertion_count += 1\n",
    "            assertion_errors += customError(key, 'superset')\n",
    "    \n",
    "    if assertion_count > 0:\n",
    "        raise AssertionError(assertion_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in df.iterrows():\n",
    "    try:\n",
    "        excelAssertions(row)\n",
    "#         print()\n",
    "    except AssertionError as e:\n",
    "        print(index)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON_files_with_gender/5c1f4ec11e67d78e279d0505.json\n",
      "JSON_files_with_gender/5c3ef32e1e67d78e27f52120.json\n",
      "JSON_files_with_gender/5c497ebf1e67d78e27205222.json\n",
      "JSON_files_with_gender/5c1ea0a81e67d78e279ae6c5.json\n",
      "JSON_files_with_gender/5c32df6b1e67d78e27cf59df.json\n",
      "JSON_files_with_gender/5c482d841e67d78e271c28fd.json\n",
      "JSON_files_with_gender/5c3d7f2f1e67d78e27f03374.json\n",
      "JSON_files_with_gender/5c53e08b1e67d78e27404c69.json\n",
      "JSON_files_with_gender/5c480de41e67d78e271b5684.json\n",
      "JSON_files_with_gender/5c47f7b01e67d78e271b0b6c.json\n",
      "JSON_files_with_gender/5c29a2d01e67d78e27b6f656.json\n",
      "JSON_files_with_gender/5c3466b21e67d78e27d40c2f.json\n",
      "JSON_files_with_gender/5c1dd3051e67d78e27981aa4.json\n",
      "JSON_files_with_gender/5c3e18ac1e67d78e27f24c0d.json\n",
      "JSON_files_with_gender/5c343c861e67d78e27d31ccf.json\n",
      "JSON_files_with_gender/5c535aed1e67d78e273ee007.json\n",
      "JSON_files_with_gender/5c480a051e67d78e271b45e1.json\n",
      "JSON_files_with_gender/5c15646b1e67d78e2771b011.json\n",
      "JSON_files_with_gender/5c3ecf861e67d78e27f448a4.json\n",
      "JSON_files_with_gender/5c53e7831e67d78e274060bd.json\n",
      "JSON_files_with_gender/5c1f24a21e67d78e279c4dce.json\n",
      "JSON_files_with_gender/5c5d45361e67d78e275e66be.json\n",
      "JSON_files_with_gender/5c3ed0931e67d78e27f44db6.json\n",
      "JSON_files_with_gender/5c2a7c6b1e67d78e27b9493f.json\n",
      "JSON_files_with_gender/5c207eef1e67d78e279f0ba2.json\n",
      "JSON_files_with_gender/5c2866051e67d78e27b3da81.json\n",
      "JSON_files_with_gender/5c1dc55f1e67d78e2797eb5e.json\n",
      "JSON_files_with_gender/5c3ebd0a1e67d78e27f40f28.json\n",
      "JSON_files_with_gender/5c5dc09d1e67d78e275fe050.json\n",
      "JSON_files_with_gender/5c52b94d1e67d78e273d1124.json\n",
      "JSON_files_with_gender/5c29daeb1e67d78e27b7b2bd.json\n",
      "JSON_files_with_gender/5c53d38f1e67d78e274020f7.json\n",
      "JSON_files_with_gender/5c28893a1e67d78e27b46332.json\n",
      "JSON_files_with_gender/5c2851051e67d78e27b39e79.json\n",
      "JSON_files_with_gender/5c1f169f1e67d78e279c1ec6.json\n",
      "JSON_files_with_gender/5c5281be1e67d78e273bebaa.json\n",
      "JSON_files_with_gender/5c14755d1e67d78e276f47ba.json\n",
      "JSON_files_with_gender/5c3e42eb1e67d78e27f2ca7c.json\n",
      "JSON_files_with_gender/5c5290441e67d78e273c1d6e.json\n",
      "JSON_files_with_gender/5c3443871e67d78e27d331b0.json\n",
      "JSON_files_with_gender/5c3da1311e67d78e27f10002.json\n",
      "JSON_files_with_gender/5c540ae01e67d78e274141ea.json\n",
      "JSON_files_with_gender/5c32ec6e1e67d78e27cf7d89.json\n",
      "JSON_files_with_gender/5c33152f1e67d78e27d01a48.json\n",
      "JSON_files_with_gender/5c5d271c1e67d78e275d9753.json\n",
      "JSON_files_with_gender/5c5d0e1f1e67d78e275d41c0.json\n",
      "JSON_files_with_gender/5c4a20781e67d78e27222bab.json\n",
      "JSON_files_with_gender/5c5de6ee1e67d78e2760579f.json\n",
      "JSON_files_with_gender/5c1dfd991e67d78e2799083f.json\n",
      "JSON_files_with_gender/5c32f2071e67d78e27cf8b76.json\n",
      "JSON_files_with_gender/5c34de311e67d78e27d55d93.json\n",
      "JSON_files_with_gender/5c2869831e67d78e27b3e81d.json\n"
     ]
    }
   ],
   "source": [
    "json_objs = {}\n",
    "\n",
    "for file in json_files:\n",
    "    print(file)\n",
    "    if file.endswith('.json'):\n",
    "        with open(file, 'r+', encoding=ENCODING) as fo:\n",
    "            file_str = fo.read().rstrip()\n",
    "        json_objs[file.split('/')[-1]] = json.loads(file_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_fields = ['verb_index', 'speaker_index', 'quote_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonAssertions(json):\n",
    "    for quote_record in json:\n",
    "        fields = ['verb', 'verb_index', 'quote', 'quote_index', 'speaker',\n",
    "                  'speaker_index', 'speaker_gender', 'reference']\n",
    "        for field in fields:\n",
    "            assert field in quote_record.keys(), \"FAILED ASSERTION: Fields in quote record: \" + field\n",
    "        \n",
    "        assert len(quote_record['quote']) > 0, \"FAILED ASSERTION: Empty quote\"\n",
    "        assert len(quote_record['quote_index']) > 0, \"FAILED ASSERTION: Empty quote-index\"\n",
    "        assert len(quote_record['reference']) > 0, \"FAILED ASSERTION: Empty reference\"\n",
    "        \n",
    "        if len(quote_record['verb']) == 0:\n",
    "            assert len(quote_record['verb_index']) == 0, \"FAILED ASSERTION: verb empty, verb-index non-empty\"\n",
    "        if len(quote_record['verb_index']) == 0:\n",
    "            assert len(quote_record['verb']) == 0, \"FAILED ASSERTION: verb-index non-empty, verb-index empty\"\n",
    "            \n",
    "        if len(quote_record['speaker']) == 0:\n",
    "            assert len(quote_record['speaker_index']) == 0, \"FAILED ASSERTION: speaker empty, speaker-index non-empty\"\n",
    "        if len(quote_record['speaker_index']) == 0:\n",
    "            assert len(quote_record['speaker']) == 0, \"FAILED ASSERTION: speaker non-empty, speaker-index empty\"\n",
    "            \n",
    "        assert quote_record['speaker_gender'] in ['male', 'female', 'unknown'], \"FAILED ASSERTION: speaker_gender \" + quote_record['speaker_gender']\n",
    "        \n",
    "        tuples = []\n",
    "        \n",
    "        for field in index_fields:\n",
    "            if len(quote_record[field]) > 0:\n",
    "                index_tuple = eval(quote_record[field])\n",
    "                tuples.append(index_tuple)\n",
    "                \n",
    "                assert index_tuple[1] > index_tuple[0], \"FAILED ASSERTION: bad tuple \" + quote_record[field]\n",
    "                \n",
    "                assert len(quote_record[field.split('_index')[0]]) == index_tuple[1] - index_tuple[0], (\n",
    "                                \"FAILED ASSERTION: \" + field + \" length mismatch \") + quote_record[field]\n",
    "            \n",
    "        tuple_set = set(tuples)\n",
    "        assert len(tuple_set) == len(tuples), \"FAILED ASSERTION: distinct indices\"\n",
    "            \n",
    "        for i,t_1 in enumerate(tuples):\n",
    "            others = tuples[:i] + tuples[i+1:]\n",
    "            for t_2 in others:\n",
    "                assert t_1[0] != t_2[1], \"FAILED ASSERTION: overlap in indices\"\n",
    "                assert t_1[1] != t_2[0], \"FAILED ASSERTION: overlap in indices\"\n",
    "                \n",
    "                \n",
    "        if len(quote_record['verb']) > 0:\n",
    "            assert ' ' not in quote_record['verb'], \"FAILED ASSERTION: verb contains space \" + quote_record['verb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5c2851051e67d78e27b39e79.json\n",
      "FAILED ASSERTION: Fields in quote record: speaker_gender\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fname in json_objs.keys():\n",
    "    try:\n",
    "        jsonAssertions(json_objs[fname])\n",
    "    except AssertionError as e:\n",
    "        print(fname)\n",
    "        print(e)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_list = []\n",
    "for fname in json_objs.keys():\n",
    "    for quote_record in json_objs[fname]:\n",
    "        verb = quote_record['verb']\n",
    "        if len(verb) > 0:\n",
    "            verb_list.append(verb.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['avoue', 'était', 'remémore', 'entendre', 'tonné', 'valoir', 'relaté', 'est', 'estime', 'raconté', 'observe', 'réfuté', 'enchaîné', 'note', 'demandé', 'avance', 'dise', 'considérant', 'annoncé', 'ordonne', 'adressé', 'cité', 'constaté', 'indiquant', 'dénoncer', 'réagi', 'préciser', 'lâche', 'souri', 'jugé', 'lance', 'signale', 'reconnu', 'estimé', 'évoqué', 'accusent', 'soulève', 'souligné', 'révèle', 'disait', 'remarquer', 'accuse', 'commente', 'suggérer', 'évoquées', 'ajouté', 'plaidé', 'déploré', 's’excite', 'indique', 'laisse', 'confirmé', 'jugent', 'insurgé', 'répliquent', 'donne', 'promet', 'demeurent', 'dénoncé', 'répète', 'plaignent', 'propose', 'répondu', 'déclare', 'expliqué', 'prévoit', 'dit', 'insisté', 'souligne', 'plaidait', 'exige', 'prétextant', 'exprimé', 'justifiant', 'admis', 'rappelant', 'dénoncent', 'constate', 'demande', 'rappelle', 'critique', 'rétorqué', 'espère', 'affirmé', 'a', 'poursuivi', 'précisant', 'croit', 'réjouit', 'disant', 'dite', 'ajoute', 'recommandait', 'déplore', 'reproche', 'avertit', 'explique', 'indiqué', 'mentionné', 'illustre', 'soutenait', 'écrit', 'raconte', 'précise', 'conclut', 'prévenu', 'recommande', 'appelle', 'rapporté', 'déclaré', 'lisait', 'défend', \"s'étonne\", 'souhaité', 'lire', 'témoigné', 'confie', 'invite', 'soutient', 'souhaite', 'affirme', 'exprime', 'proposé', 'questionne', 'ironisé', 'soupirent', 'admet', 'dire', 'rapporte', 'analyse', 'arguait', 'inquiétée', 'évoquant', 'ajoutant', 'soutenu', 'rétorque', 'conclu', 'lit', 'désole', 'poursuit', 'savoir', 'annonce', 'remémoré', 'reconnaît', 'déclarait', 'affirmait', 'suggéré', 'mentionne', 'relate', 'confirme', 'indigné', 'juge', 'plaide', 'insiste', 'citant', 'commenté', 'estiment', 'décrit', 'assure', 'extasié', 'affirmant', 'prévient', 'précisé', 'veut', 'lancé', 'reconnaissant']\n"
     ]
    }
   ],
   "source": [
    "print(list(set(verb_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('verbs_fr.txt', 'w+') as fo:\n",
    "    for verb in list(set(verb_list)):\n",
    "        fo.write(verb + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats on quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "715"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_quotes = []\n",
    "for fname in json_objs.keys():\n",
    "    num_quotes.append(len(json_objs[fname]))\n",
    "    \n",
    "sum(num_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_syntactic_quotes = []\n",
    "for fname in json_objs.keys():\n",
    "    f_quotes = 0\n",
    "    for quote_record in json_objs[fname]:\n",
    "        if (len(quote_record['verb']) > 0) and (len(quote_record['speaker']) > 0):\n",
    "            f_quotes += 1\n",
    "    num_syntactic_quotes.append(f_quotes)\n",
    "    \n",
    "sum(num_syntactic_quotes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
