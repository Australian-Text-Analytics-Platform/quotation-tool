{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aec87485",
   "metadata": {},
   "source": [
    "# Semantic Tagger (English)\n",
    "\n",
    "In this notebook, you will use the [Python Multilingual Ucrel Semantic Analysis System (PyMUSAS)](https://ucrel.github.io/pymusas/) to tag your text data so that you can extract token level semantic tags from the tagged text. PyMUSAS is a rule based token and Multi Word Expression (MWE) semantic tagger. The tagger can support any semantic tagset; however the currently released tagset is for the [Ucrel Semantic Analysis System (USAS)](https://ucrel.lancs.ac.uk/usas/) semantic tags. \n",
    "\n",
    "In addition to the USAS tags, you will also see the lemmas and Part-of-Speech (POS) tags in the text. For English, the tagger also identifies and tags Multi Word Expressions (MWE), i.e., expressions formed by two or more words that behave like a unit such as 'South Australia'. See further [this article](https://www.sciencedirect.com/science/article/abs/pii/S0885230805000112?via%3Dihub) for an evaluation on the tagger’s MWE capabilities for English.  \n",
    "\n",
    "\n",
    "**Note:** This code has been adapted (with permission) from the [PyMUSAS GitHub page](https://github.com/UCREL/pymusas) and modified to run on a Jupyter Notebook. PyMUSAS is an open-source project that has been created and funded by the [University Centre for Computer Corpus Research on Language (UCREL)](https://ucrel.lancs.ac.uk/) at [Lancaster University](https://www.lancaster.ac.uk/). For more information about PyMUSAS, please visit [the Usage Guides page](https://ucrel.github.io/pymusas/). An evaluation of the accuracy of the English semantic tagger is included in [this paper](https://www.lancaster.ac.uk/staff/rayson/publications/usas_lrec04ws.pdf).\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>User guide to using a Jupyter Notebook</b> \n",
    "\n",
    "If you are new to Jupyter Notebook, feel free to take a quick look at [this user guide](https://github.com/Australian-Text-Analytics-Platform/semantic-tagger/blob/main/documents/jupyter-notebook-guide.pdf) for basic information on how to use a notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c2e31b",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "Before you begin, you need to import the SemanticTagger and the necessary libraries and initiate them to run in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d2481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the SemanticTagger\n",
    "print('Loading SemanticTagger...')\n",
    "from semantic_tagger_en import SemanticTagger, DownloadFileLink\n",
    "\n",
    "# initialize the SemanticTagger\n",
    "st = SemanticTagger()\n",
    "print('Finished loading.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec771d6f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Multi Word Expression (MWE)</b> \n",
    "    \n",
    "Below, you can choose to also identify and tag Multi Word Expressions (MWE), i.e., expressions formed by two or more words that behave like a unit such as 'South Australia'. However, please be aware that selecting the MWE option will make the extraction process much slower.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed6235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select whether to include mwe extractions\n",
    "st.loading_tagger_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cdbd1e",
   "metadata": {},
   "source": [
    "## 2. Load the data\n",
    "This notebook will allow you to tag text data in a text file (or a number of text files). Alternatively, you can also tag text inside a text column inside your excel spreadsheet ([see an example here](https://github.com/Sydney-Informatics-Hub/HASS-29_Quotation_Tool/blob/main/documents/sample_texts.xlsx)).  \n",
    "\n",
    "<table style='margin-left: 10px'><tr>\n",
    "<td> <img src='./img/txt_icon.png' style='width: 45px'/> </td>\n",
    "<td> <img src='./img/xlsx_icon.png' style='width: 55px'/> </td>\n",
    "<td> <img src='./img/csv_icon.png' style='width: 45px'/> </td>\n",
    "<td> <img src='./img/zip_icon.png' style='width: 45px'/> </td>\n",
    "</tr></table>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Uploading your text files</b> \n",
    "    \n",
    "If you have a large number of text files (more than 10MB in total), we suggest you compress (zip) them and upload the zip file instead. If you need assistance on how to compress your file, please check [the user guide](https://github.com/Australian-Text-Analytics-Platform/semantic-tagger/blob/main/documents/jupyter-notebook-guide.pdf) for more info. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Large file upload</b> \n",
    "    \n",
    "If you have ongoing issues with the file upload, please re-launch the notebook via Binder again. If the issue persists, consider restarting your computer.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a1ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the text files and/or excel spreadsheets onto the system\n",
    "display(st.upload_box)\n",
    "print('Uploading large files may take a while. Please be patient...')\n",
    "print('\\033[1mPlease wait and do not press any buttons until the progress bar appears...\\033[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70453326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display uploaded text\n",
    "n=5\n",
    "\n",
    "st.text_df.head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7a4413",
   "metadata": {},
   "source": [
    "## 3. Add Semantic Tags\n",
    "Once your texts have been uploaded, you can begin to add semantic tags to the texts and download the results to your computer. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tools:</b>    \n",
    "\n",
    "- PyMUSAS RuleBasedTagger: for adding USAS token tags.\n",
    "- spaCy: for adding lemma and POS tags.\n",
    "    \n",
    "<b>Note:</b> this tool uses spaCy to tokenize the text, which initially splits the text into tokens based on whitespace characters, and then applies language specific rules to further refine the outcome. For example, the word “don’t” does not contain whitespace, but would be split into two tokens: “do” and “n’t”, whereas “U.K.” would remain as one token. For more information about spaCy tokenizer, please visit [this page](https://spacy.io/usage/linguistic-features#tokenization).\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Memory limitation in Binder</b> \n",
    "    \n",
    "The free Binder deployment is only guaranteed a maximum of 2GB memory. Processing very large text files may cause the session (kernel) to re-start due to insufficient memory. Check [the user guide](https://github.com/Australian-Text-Analytics-Platform/semantic-tagger/blob/main/documents/jupyter-notebook-guide.pdf) for more info. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Large corpus</b> \n",
    "    \n",
    "Whilst using this tool with a large corpus is possible, this tool is more appropriate for use with a smaller corpus (<1,000 text files). This is because adding semantic tags to each token in the texts may take a while, especially if MWE are also extracted from the texts. Be patient while the corpus is being semantically tagged. As a guideline, a corpus with a file size of 0.66 MB (~600 newspaper articles in plain text format) can take 6-7 minutes before tagging is completed when MWE is selected and about two minutes when MWE is not selected. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16e8711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add semantic taggers to the uploaded texts\n",
    "print('Processing and adding semantic tags to your texts.')\n",
    "print('The counter will start soon. Please be patient...')\n",
    "st.tag_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb13ad6b",
   "metadata": {},
   "source": [
    "Once you have tagged the texts, you can display them in the dataframe (table format) below. All you need to do is to select the tagged text you wish to display and click the 'Display tagged text' button. You can also filter the text to only display certain pos tags or usas tags only (multiple filter selections are possible). You can choose to display one semantically-tagged text file or compare two semantically-tagged text files with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c72b328",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display tagged text\n",
    "st.display_two_tag_texts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c28341e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>What information is included in the above table?</b> \n",
    "\n",
    "**token:** each token in the sentence, e.g., word, punctuation, etc.\n",
    "    \n",
    "**lemma** the lemma of the token.\n",
    "    \n",
    "**pos:** part-of-speech tag of the token.\n",
    "    \n",
    "**start_index/end_index (mwe option only):** the start and end indices of the token(s).\n",
    "    \n",
    "**mwe (mwe option only):** whether the token is part of a multi-word expression.\n",
    "    \n",
    "**usas_tags:** the the Ucrel Semantic Analysis System (USAS) sematic tag of the token.\n",
    "    \n",
    "**usas_tags_def:** the definition of the USAS tag of the token.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86559f23",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Analyse the tagged text</b> \n",
    "\n",
    "You can also analyse the tagged texts using simple visualizations below. To do so, please select the text (including 'all texts') and the entity to analyse, and click the 'Show top entities' button. To check the top words in each entity (e.g., top USAS tag 'Personal names'), select the drop down options on the right (multiple selections possible) and click 'Show top words' to display. To save the displayed charts, click the 'Save analysis' button. Make sure you change n [number] in ‘Select n’ to display the top 5, 10, 15 etc entities or words. You can just use the visualisation on the left-hand side (if you analyse ‘all texts’ or one specific text/file) or you can use both visualisations to compare two texts/files with each other. \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9524116",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# analyse tagged texts\n",
    "st.analyse_two_tags()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfd85ae",
   "metadata": {},
   "source": [
    "## 4. Save tagged texts\n",
    "Finally, you can run the below code to save the tagged texts into a comma separated file (.csv) or an excel spreadsheet (.xlsx) containing the tagged texts, or a zip of pseudo-xml (.txt) tagged text files. You can then download them to your local computer and use them for further analysis if you wish.  \n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Windows users</b> \n",
    "\n",
    "For Windows users, we suggest to download the tagged texts in excel or pseudo-xml format to ensure the non-English characters are encoded properly (MacOS users can still download the tagged texts in csv format and use the Numbers app to read them). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5898c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tagged texts\n",
    "st.save_options()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
