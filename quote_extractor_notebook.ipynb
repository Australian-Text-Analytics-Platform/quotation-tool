{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c2662a3",
   "metadata": {},
   "source": [
    "# QuotationTool\n",
    "In this notebook, you will use the *QuotationTool* to extract quotes from a list of texts. In addition to extracting the quotes, the tool also provides information about who the speakers are, the location of the quotes (and the speakers) within the text, the identified named entities, etc., which can be useful for your text analysis.  \n",
    "\n",
    "**Note:** This code has been adapted (with permission) from the [GenderGapTracker GitHub page](https://github.com/sfu-discourse-lab/GenderGapTracker/tree/master/nlp/english) and modified to run on a Jupyter Notebook. The quotation tool’s accuracy rate is evaluated in [this article](https://doi.org/10.1371/journal.pone.0245533).\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>User guide to using a Jupyter Notebook</b> \n",
    "\n",
    "If you are new to Jupyter Notebook, feel free to take a quick look at [this user guide](https://github.com/Australian-Text-Analytics-Platform/quotation-tool/blob/main/documents/jupyter-notebook-guide.pdf) for basic information on how to use a notebook.\n",
    "</div>\n",
    "\n",
    "### Quotation Tool User Guide\n",
    "\n",
    "For instructions on how to use the Quotation Tool, please refer to the [Quotation Tool User Guide](documents/quotation_help_pages.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc99ca86",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "Before you begin, you need to import the QuotationTool and the necessary libraries and initiate them to run in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6720419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the QuotationTool\n",
    "import warnings\n",
    "from extract_display_quotes import QuotationTool, DownloadFileLink\n",
    "\n",
    "# initialize the QuotationTool\n",
    "qt = QuotationTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a9cb8a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Installing Libraries</b> \n",
    "\n",
    "The requirements file <b>environment.yml</b> is included with this notebook. Take a look inside to find out what libraries you have just installed with the above command.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf517c9",
   "metadata": {},
   "source": [
    "## 2. Load the data\n",
    "This notebook will allow you to extract quotes directly from a text file (or a number of text files). Alternatively, you can also extract quotes from a text column inside your excel spreadsheet ([see an example here](https://github.com/Australian-Text-Analytics-Platform/quotation-tool/blob/main/documents/sample_texts.xlsx?raw=true)).  \n",
    "\n",
    "<table style='margin-left: 10px'><tr>\n",
    "<td> <img src='./img/txt_icon.png' style='width: 45px'/> </td>\n",
    "<td> <img src='./img/xlsx_icon.png' style='width: 55px'/> </td>\n",
    "<td> <img src='./img/csv_icon.png' style='width: 45px'/> </td>\n",
    "<td> <img src='./img/zip_icon.png' style='width: 45px'/> </td>\n",
    "</tr></table>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Uploading your text files</b> \n",
    "    \n",
    "If you have a large number of text files (more than 10MB in total), we suggest you compress (zip) them and upload the zip file instead. If you need assistance on how to compress your file, please check [the user guide](https://github.com/Australian-Text-Analytics-Platform/quotation-tool/blob/main/documents/jupyter-notebook-guide.pdf) for more info. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Large file upload</b> \n",
    "    \n",
    "If you have ongoing issues with the file upload, please re-launch the notebook via Binder again. If the issue persists, consider restarting your computer.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad98bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the text files and/or excel spreadsheets onto the system\n",
    "display(qt.upload_box)\n",
    "print('Uploading large files may take a while. Please be patient.')\n",
    "print('\\033[1mPlease wait and do not press any buttons until the progress bar appears...\\033[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c700ef8b",
   "metadata": {},
   "source": [
    "Once your files are uploaded, you can see a preview of the text in a table format (pandas dataframe).  \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tools:</b>    \n",
    "    \n",
    "- nltk: for sentence tokenization\n",
    "- spaCy: for text cleaning and normalisation\n",
    "- pandas: for storing and displaying in dataframe (table) format\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Specify the number of rows to display</b> \n",
    "    \n",
    "By default, you will preview the first 5 rows of the extracted quotes in a pandas dataframe (table) format. However, you can preview more or less rows by specifying the number of rows you wish to display in the variable 'n' below. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d35f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the number of rows you wish to display\n",
    "n=5\n",
    "\n",
    "# display a preview of the pandas dataframe\n",
    "qt.text_df.head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4039347d",
   "metadata": {},
   "source": [
    "## 3. Extract the quotes\n",
    "Once your texts have been stored in a pandas dataframe, you can begin to extract the quotes from the texts. You can also extract named entities from your text by setting the named entities you wish to include in the below *inc_ent* variable. If you are extracting quotes from a lot of texts, be patient. As a guideline, for a corpus with a file size of 54.13 MB (~26,000 newspaper articles in plain text format), it can take ca 45 minutes to extract quotes.    \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tools:</b>    \n",
    "\n",
    "- quote_extractor: for extracting quotes and speakers\n",
    "- spaCy: for extracting named entities\n",
    "    \n",
    "<b>Note:</b> this tool uses spaCy to tokenize the text, which initially splits the text into tokens based on whitespace characters, and then applies language specific rules to further refine the outcome. For example, the word “don’t” does not contain whitespace, but would be split into two tokens: “do” and “n’t”, whereas “U.K.” would remain as one token. For more information about spaCy tokenizer, please visit [this page](https://spacy.io/usage/linguistic-features#tokenization).\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Specify the number of rows to display</b> \n",
    "    \n",
    "By default, you will preview the first 5 rows of the extracted quotes in a pandas dataframe (table) format. However, you can preview more or less rows by specifying the number of rows you wish to display in the variable 'n' below. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Memory limitation in Binder</b> \n",
    "    \n",
    "The free Binder deployment is only guaranteed a maximum of 2GB memory. Processing very large text files may cause the session (kernel) to re-start due to insufficient memory. Check [the user guide](https://github.com/Sydney-Informatics-Hub/HASS-29_Quotation_Tool/blob/main/documents/jupyter-notebook-guide.pdf) for more info. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab19f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the named entities you wish to include below\n",
    "inc_ent = ['ORG','PERSON','GPE','NORP','FAC','LOC']\n",
    "\n",
    "# specify the number of rows you wish to display\n",
    "n=5\n",
    "\n",
    "# extract quotes from the text and preview them in a pandas dataframe (table) format\n",
    "quotes_df = qt.get_quotes(inc_ent)\n",
    "\n",
    "# display a preview of the pandas dataframe\n",
    "quotes_df.head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079bc8a7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>What information is included in the above table?</b> \n",
    "\n",
    "In general, the quotes are extracted either based on syntactic or heuristic rules. Some quotes can be stand-alone in a sentence, or followed by another quote (floating quote) from the same speaker. Please refer to [this document](https://doi.org/10.1371/journal.pone.0245533.s001) for further information about the quote extraction process.  \n",
    "    \n",
    "**text_id:** the unique ID of the text.\n",
    "    \n",
    "**text_name** the name of the text, i.e., the name of the .txt files or the 'text_name' column in the excel spreadsheet.\n",
    "    \n",
    "**quote_id/speaker_id:** the unique ID of the extracted quote/speaker.\n",
    "    \n",
    "**quote/speaker:** the content of the extracted quote and the speaker.\n",
    "    \n",
    "**verb:** the verb used to determine the extracted quote.\n",
    "    \n",
    "**quote_index/speaker_index/verb_index:** the location of the first and the last characters of the extracted quote/speaker/verb in the text.\n",
    "    \n",
    "**quote_entities/speaker_entities:** the entity name and type of the entities identified in the extracted quote/speaker.\n",
    "    \n",
    "**quote_token_count:** the length of the extracted quote (in character).\n",
    "    \n",
    "**quote_type:** the type of quote based on how it is extracted.\n",
    "    \n",
    "**floating_quote:** whether the extracted quote is a floating quote, i.e., a follow up quote from the same speaker (The value TRUE here means that the quote is a floating quote, while FALSE means that the quote is not a floating quote).\n",
    "\n",
    "**Quotation symbols:** Q (Quotation mark), S (Speaker), V (Verb), C (Content).  \n",
    "\n",
    "**Named Entities:**  PERSON (People, including fictional), NORP (Nationalities or religious or political groups), FAC (Buildings, airports, highways, etc.), ORG (Companies, agencies, institutions, etc.), GPE (Countries, cities, states), LOC (Non-GPE locations, mountain ranges, bodies of water).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70be6223",
   "metadata": {},
   "source": [
    "## 4. Display the quotes\n",
    "Once you have extracted the quotes, you can see a preview of the quotes using spaCy's visualisation tool, displaCy. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tools:</b>    \n",
    "\n",
    "- displaCy: for displaying quotes, speakers and named entities\n",
    "- ipywidgets: for interactive tool\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Select the text and the entities to show</b> \n",
    "\n",
    "In order to preview the extracted information, select the text you wish to analyse and which entities to show. Then, you can click the ***Preview*** button to display them and the ***Save Preview*** button to save them as an html file. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e536e55b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display a preview of the extracted quotes, speakers and entities within the text\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "qt.analyse_quotes(inc_ent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5f4dc4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Select the text and the entities to show</b> \n",
    "\n",
    "You can also display the top named entitites identified in the quotes and/or speakers. You just need to select the text to analyse (option to analyse 'all texts' is also available), whether to display the identified entities in the speakers and/or quotes, whether to display the entity names and/or types, the number of top entities to display and finally, click the ***Show Top Entities*** and ***Save Top Entities*** buttons to display and save them, respectively. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a92980",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check the top named entities identified in the quotes and/or speakers\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "qt.analyse_entities(inc_ent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e56460",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Capitalized words</b> \n",
    "\n",
    "Please note that lowercase or UPPERCASE words such as quote, QUOTE, Quote, etc. are recognised as different words by the tool, so you may see that they are counted differently in the above analysis.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3607fd4b",
   "metadata": {},
   "source": [
    "## 5. Save the quotes\n",
    "Finally, you can run the below code to save the quotes pandas dataframe into an Excel spreadsheet and download them to your local computer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "388ca926",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'warnings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwarnings\u001b[49m\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# specify output directory and file name\u001b[39;00m\n\u001b[1;32m      3\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./output/\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'warnings' is not defined"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "# specify output directory and file name\n",
    "output_dir = './output/'\n",
    "file_name = 'quotes.xlsx'\n",
    "\n",
    "# save quotes_df into an Excel spreadsheet\n",
    "from pyexcelerate import Workbook\n",
    "values = [quotes_df.columns] + list(quotes_df.values)\n",
    "wb = Workbook()\n",
    "wb.new_sheet('Sheet1', data=values)\n",
    "wb.save(output_dir + file_name)\n",
    "\n",
    "# download quotes_df to your computer\n",
    "print('Click below to download:')\n",
    "display(DownloadFileLink(output_dir + file_name, 'quotes.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fef16122",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test Quote aggregation\n",
    "import sys\n",
    "from config import config\n",
    "sys.path.insert(0,'./GenderGapTracker/nlp/english')\n",
    "from quote_extractor import QuoteExtractor\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy_experimental.coref.coref_component import DEFAULT_COREF_MODEL\n",
    "from spacy_experimental.coref.coref_util import DEFAULT_CLUSTER_PREFIX\n",
    "config_coref={\n",
    "    \"model\": DEFAULT_COREF_MODEL,\n",
    "    \"span_cluster_prefix\": DEFAULT_CLUSTER_PREFIX,\n",
    "}\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "# nlp.add_pipe(\"experimental_coref\", config=config_coref)\n",
    "\n",
    "\n",
    "qt = QuoteExtractor(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fd25058",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Parameter 'E' for model 'hashembed' has not been allocated yet.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m coref \u001b[38;5;241m=\u001b[39m nlp\u001b[38;5;241m.\u001b[39madd_pipe(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperimental_coref\u001b[39m\u001b[38;5;124m\"\u001b[39m, config\u001b[38;5;241m=\u001b[39mconfig_coref)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# This usually happens under the hood\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[43mcoref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m quotes_o \u001b[38;5;241m=\u001b[39m qt\u001b[38;5;241m.\u001b[39mextract_quotes(doc\u001b[38;5;241m=\u001b[39mdoc)\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/spacy/pipeline/trainable_pipe.pyx:56\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/spacy/util.py:1722\u001b[0m, in \u001b[0;36mraise_error\u001b[0;34m(proc_name, proc, docs, e)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_error\u001b[39m(proc_name, proc, docs, e):\n\u001b[0;32m-> 1722\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/spacy_experimental/coref/coref_component.py:153\u001b[0m, in \u001b[0;36mCoreferenceResolver.predict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    150\u001b[0m     out\u001b[38;5;241m.\u001b[39mappend([])\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m scores, idxs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# idxs is a list of mentions (start / end idxs)\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# each item in scores includes scores and a mapping from scores to mentions\u001b[39;00m\n\u001b[1;32m    156\u001b[0m ant_idxs \u001b[38;5;241m=\u001b[39m idxs\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/thinc/model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/thinc/layers/with_array.py:36\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     33\u001b[0m     model: Model[SeqT, SeqT], Xseq: SeqT, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m     34\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[SeqT, Callable]:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Xseq, Ragged):\n\u001b[0;32m---> 36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], \u001b[43m_ragged_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Xseq, Padded):\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _padded_forward(model, Xseq, is_train))\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/thinc/layers/with_array.py:91\u001b[0m, in \u001b[0;36m_ragged_forward\u001b[0;34m(model, Xr, is_train)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ragged_forward\u001b[39m(\n\u001b[1;32m     88\u001b[0m     model: Model[SeqT, SeqT], Xr: Ragged, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m     89\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Ragged, Callable]:\n\u001b[1;32m     90\u001b[0m     layer: Model[ArrayXd, ArrayXd] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 91\u001b[0m     Y, get_dX \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataXd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dYr: Ragged) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Ragged:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Ragged(get_dX(dYr\u001b[38;5;241m.\u001b[39mdataXd), dYr\u001b[38;5;241m.\u001b[39mlengths)\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/thinc/layers/concatenate.py:57\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m---> 57\u001b[0m     Ys, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train) \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers])\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Ys[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     59\u001b[0m         data_l, backprop \u001b[38;5;241m=\u001b[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/thinc/layers/concatenate.py:57\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m---> 57\u001b[0m     Ys, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers])\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Ys[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     59\u001b[0m         data_l, backprop \u001b[38;5;241m=\u001b[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/thinc/layers/hashembed.py:62\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, ids, is_train)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     60\u001b[0m     model: Model[Ints1d, OutT], ids: Ints1d, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m     61\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m---> 62\u001b[0m     vectors \u001b[38;5;241m=\u001b[39m cast(Floats2d, \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_param\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     63\u001b[0m     nV \u001b[38;5;241m=\u001b[39m vectors\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     64\u001b[0m     nO \u001b[38;5;241m=\u001b[39m vectors\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/atap/lib/python3.10/site-packages/thinc/model.py:235\u001b[0m, in \u001b[0;36mModel.get_param\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown param: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params\u001b[38;5;241m.\u001b[39mhas_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid, name):\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has not been allocated yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m     )\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params\u001b[38;5;241m.\u001b[39mget_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid, name)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Parameter 'E' for model 'hashembed' has not been allocated yet.\""
     ]
    }
   ],
   "source": [
    "text = '''\n",
    "\n",
    "Senator Matt Canavan, an ally of new Nationals leader Barnaby Joyce, has accused the National Farmers' Federation of hypocrisy for advocating no net emissions of greenhouse gases by 2050 while objecting to land-clearing rules that have helped reduce Australia's carbon dioxide emissions.\n",
    "\n",
    "The criticism reflects a split within agriculture-based organisations about the benefits or harm of Australia committing to what is known as the CN2050 target at a November United Nations climate conference in Glasgow.\n",
    "\n",
    "\"I find their position absolutely incoherent, the way they have us reducing emissions by 50 per cent through government locking up huge areas of land through tree-clearing laws, which the NFF are opposed to,\" Senator Canavan, the Nationals' deputy Senate leader, said in an interview.\n",
    "\n",
    "\"The reason we are meeting Kyoto [emissions targets] with a spillover - that is all from 6 million hectares of pastoral land reforested from land-use regulations.\n",
    "\n",
    "\"I suppose they are not the only political organisation to have hypocritical policy positions.\"\n",
    "\n",
    "Some National Party politicians, especially in Victoria, have expressed concerns that under Mr Joyce, who was re-elected leader on June 21, the party will become reluctant to support or agree to more stringent climate policies.\n",
    "\n",
    "Prime Minister Scott Morrison has expressed a desire to reach the 2050 target but has not committed the government to it.\n",
    "\n",
    "The National Farmers' Federation supports what it calls a 2050 \"net zero aspiration\" target. The Business Council of Australia, which represents large companies, supports the target without qualification.\n",
    "\n",
    "Responding to Senator Canavan's comments, NFF chief executive Tony Mahar said the group's approach was consistent and it wanted the debate to focus on more substantial problems, including the policies, technology and funding needed to lower emissions.\n",
    "\n",
    "\"We want to see farmers rewarded for their role in lowering emissions, rather than the policies of the past which saw swaths of private farmland locked up with no recognition and no compensation,\" he said.\n",
    "\n",
    "\"Land-clearing laws saw farmers do the heavy lifting to meet Australia's Kyoto commitments. It was a kick in the guts we haven't forgotten. Now, we want to be part of the solution in a way that recognises and rewards our contribution.\"\n",
    "\n",
    "The leader of the Nationals Victoria, Peter Walsh, acknowledged that his division had considered separating from the rest of the party after Mr Joyce was re-elected leader because of his expressed scepticism about climate policies.\n",
    "\n",
    "\"Victorian industry and the Victorian community expect their government to do more on climate change than our Queensland cousins,\" Mr Walsh said. \"The agriculture industry doesn't want to be carved out [of a climate agreement]. Everyone wants to know what the plan is or if you are part of the discussion.\"\n",
    "\n",
    "Australia's greenhouse gas emissions, which represent about 1.3 per cent of the world's, have declined 22.6 per cent since their peak in the 2007 financial year, according to the Department of Industry, Science, Energy and Resources.\n",
    "\n",
    "The International Energy Agency said in May that, to achieve no net emissions on a global basis by 2050, nuclear power would be needed to back up wind and solar power.\n",
    "\n",
    "Key pointsThe senator said the farmers' federation's position was 'incoherent'.\n",
    "\n",
    "He said they can't support net zero emissions and oppose land-clearance restrictions.\n",
    "\n",
    "'''\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "coref = nlp.add_pipe(\"experimental_coref\", config=config_coref)\n",
    "# This usually happens under the hood\n",
    "processed = coref(doc)\n",
    "\n",
    "quotes_o = qt.extract_quotes(doc=doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8cfb012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quote_start(quote):\n",
    "    '''\n",
    "    Combine all spans of speaker, quote and verb and output the start of the \n",
    "    '''\n",
    "    names = ['speaker_index', 'quote_index', 'verb_index']\n",
    "    span = ()\n",
    "    for n in names:\n",
    "        if sum(eval(quote[n])):\n",
    "            span += eval(quote[n])\n",
    "    return min(span)\n",
    "    \n",
    "quotes_s = sorted(quotes_o, key=lambda q: quote_start(q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f239708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def valid_speaker(q):\n",
    "    return not (q[\"speaker_index\"] == '(0,0)' or q[\"speaker_pos\"] == ['PRON'])\n",
    "\n",
    "def aggregate(group):\n",
    "    if len(group) <= 1:\n",
    "        return group\n",
    "    else:\n",
    "        result = group[0]\n",
    "        result['quote'] = ' \\n'.join([q['quote'] for q in group]) \n",
    "        result['quote_index'] = ', '.join([q['quote_index'] for q in group])\n",
    "        result['verb'] = ', '.join([q['verb'] for q in group])\n",
    "        result['verb_index'] = ', '.join([q['verb_index'] for q in group])\n",
    "        result['quote_token_count'] = sum([q['quote_token_count'] for q in group])\n",
    "        result['quote_type'] = ', '.join([q['quote_type'] for q in group])\n",
    "        return [result]\n",
    "\n",
    "def aggregate_quotes(quotes):\n",
    "    results = []\n",
    "    group = []\n",
    "    for q in quotes:\n",
    "        if valid_speaker(q):\n",
    "            results.extend(aggregate(group))\n",
    "            print(len(group))\n",
    "            group = [q]\n",
    "        else:\n",
    "            group.append(q)\n",
    "    results.extend(aggregate(group)) # Aggregate the very last group of quotes\n",
    "    return results\n",
    "quotes_a = aggregate_quotes(quotes_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64ec560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with pd.ExcelWriter(\"Article1.xlsx\") as writer:\n",
    "    pd.DataFrame.from_dict(quotes_o).to_excel(writer, sheet_name=\"Orig_quotes\")  \n",
    "    pd.DataFrame.from_dict(quotes_s).to_excel(writer, sheet_name=\"Sorted_quotes\")\n",
    "    pd.DataFrame.from_dict(quotes_a).to_excel(writer, sheet_name=\"Aggregated_quotes\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd0fc9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'speaker': \"Senator Canavan, the Nationals' deputy Senate leader,\",\n",
       "  'speaker_index': '(720,773)',\n",
       "  'speaker_pos': ['PROPN',\n",
       "   'PROPN',\n",
       "   'PUNCT',\n",
       "   'DET',\n",
       "   'PROPN',\n",
       "   'PART',\n",
       "   'NOUN',\n",
       "   'PROPN',\n",
       "   'NOUN',\n",
       "   'PUNCT'],\n",
       "  'quote': '\"I find their position absolutely incoherent, the way they have us reducing emissions by 50 per cent through government locking up huge areas of land through tree-clearing laws, which the NFF are opposed to \\n\"The reason we are meeting Kyoto [emissions targets] with a spillover - that is all from 6 million hectares of pastoral land reforested from land-use regulations.\\n\\n\" \\n\"\\n\\nSome National Party politicians, especially in Victoria, have expressed concerns that under Mr Joyce, who was re-elected leader on June 21, the party will become reluctant to support or agree to more stringent climate policies.\\n\\nPrime Minister Scott Morrison has expressed a desire to reach the 2050 target but has not committed the government to it.\\n\\nThe National Farmers\\' Federation supports what it calls a 2050 \" \\nthe group\\'s approach was consistent and it wanted the debate to focus on more substantial problems, including the policies, technology and funding needed to lower emissions',\n",
       "  'quote_index': '(511,717), (797,962), (1055,1474), (1694,1866)',\n",
       "  'verb': 'said, suppose, , said',\n",
       "  'verb_index': '(774,778), (964,971), , (1689,1693)',\n",
       "  'quote_token_count': 182,\n",
       "  'quote_type': 'QCQSV, Heuristic, Heuristic, SVC',\n",
       "  'is_floating_quote': False},\n",
       " {'speaker': 'he',\n",
       "  'speaker_index': '(2066,2068)',\n",
       "  'speaker_pos': ['PRON'],\n",
       "  'quote': '\"We want to see farmers rewarded for their role in lowering emissions, rather than the policies of the past which saw swaths of private farmland locked up with no recognition and no compensation \\nthat his division had considered separating from the rest of the party after Mr Joyce was re-elected leader because of his expressed scepticism about climate policies \\n\"Victorian industry and the Victorian community expect their government to do more on climate change than our Queensland cousins \\n\"\\n\\nAustralia\\'s greenhouse gas emissions, which represent about 1.3 per cent of the world\\'s, have declined 22.6 per cent since their peak in the 2007 financial year, \\nthat, to achieve no net emissions on a global basis by 2050 \\n, nuclear power would be needed to back up wind and solar power \\nthe farmers\\' federation\\'s position was \\'incoherent',\n",
       "  'quote_index': '(1869,2063), (2377,2543), (2546,2674), (2851,3015), (3133,3192), (3192,3255), (3285,3335)',\n",
       "  'verb': 'said, acknowledged, said, according to, said, said, said',\n",
       "  'verb_index': '(2069,2073), (2364,2376), (2686,2690), (3016,3028), (3121,3125), (3121,3125), (3280,3284)',\n",
       "  'quote_token_count': 151,\n",
       "  'quote_type': 'QCQSV, SVC, QCQSV, AccordingTo, SVC, SVC, SVC',\n",
       "  'is_floating_quote': False}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce357642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senator Canavan, the Nationals' deputy Senate leader, (720,773) True\n",
      "I (962,963) False\n",
      " (0,0) False\n",
      "NFF chief executive Tony Mahar (1658,1688) True\n",
      "he (2066,2068) False\n",
      "The leader of the Nationals Victoria, Peter Walsh, (2313,2363) True\n",
      "Mr Walsh (2677,2685) True\n",
      "the Department of Industry, Science, Energy and Resources.\n",
      "\n",
      " (3029,3089) True\n",
      "The International Energy Agency (3089,3120) True\n",
      "The International Energy Agency (3089,3120) True\n",
      "Key pointsThe senator (3258,3279) True\n",
      "He (3339,3341) False\n"
     ]
    }
   ],
   "source": [
    "for q in quotes_s:\n",
    "    print(q['speaker'],  q[\"speaker_index\"], not (q[\"speaker_index\"] == '(0,0)' or q[\"speaker_pos\"] == ['PRON']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b7b04bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speaker': 'I',\n",
       " 'speaker_index': '(962,963)',\n",
       " 'speaker_pos': 'PRON',\n",
       " 'quote': '\"The reason we are meeting Kyoto [emissions targets] with a spillover - that is all from 6 million hectares of pastoral land reforested from land-use regulations.\\n\\n\"',\n",
       " 'quote_index': '(797,962)',\n",
       " 'verb': 'suppose',\n",
       " 'verb_index': '(964,971)',\n",
       " 'quote_token_count': 34,\n",
       " 'quote_type': 'Heuristic',\n",
       " 'is_floating_quote': False}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_s[1]"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "50e9832c473c86713864f61257029e15f281e1af6f46dd8361ab2dc7ec7915dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
